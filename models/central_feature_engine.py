#!/usr/bin/env python3
"""
SISTEMA CENTRAL DE FEATURE ENGINEERING
======================================

Consolida TODAS as features em um sistema centralizado:
- Elimina redund√¢ncias (features calculadas 8+ vezes)
- Cache inteligente para performance
- Valida√ß√£o de qualidade
- Compatibilidade com todos os modelos
- 20+ features avan√ßadas unificadas
"""

import pandas as pd
import numpy as np
import talib
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')
from utils.technical_indicators import TechnicalIndicators

import pandas as pd
from utils.technical_indicators import (
    calculate_atr, calculate_adx, calculate_cci, calculate_obv,
    calculate_williams_r, calculate_roc, calculate_mom, calculate_trix, calculate_ultosc
)

def enrich_with_advanced_indicators(df):
    df = df.copy()
    df['atr_14'] = calculate_atr(df, 14)
    df['adx_14'] = calculate_adx(df, 14)
    df['cci_20'] = calculate_cci(df, 20)
    df['obv'] = calculate_obv(df)
    df['williams_r_14'] = calculate_williams_r(df, 14)
    df['roc_10'] = calculate_roc(df, 10)
    df['mom_10'] = calculate_mom(df, 10)
    df['trix_15'] = calculate_trix(df, 15)
    df['ultosc'] = calculate_ultosc(df, 7, 14, 28)
    return df

def merge_open_interest(candles_df, open_interest_df):
    if open_interest_df.empty:
        return candles_df
    # Faz merge por timestamp arredondado para o mesmo per√≠odo dos candles
    candles_df = candles_df.copy()
    open_interest_df = open_interest_df.copy()
    open_interest_df['timestamp'] = pd.to_datetime(open_interest_df['timestamp'])
    candles_df['timestamp'] = pd.to_datetime(candles_df['timestamp'])
    merged = pd.merge_asof(candles_df.sort_values('timestamp'), open_interest_df.sort_values('timestamp'), on='timestamp', direction='backward')
    merged = merged.rename(columns={
        'sumOpenInterest': 'open_interest',
        'sumOpenInterestValue': 'open_interest_value'
    })
    return merged

def merge_funding_rate(candles_df, funding_rate_df):
    if funding_rate_df.empty:
        return candles_df
    candles_df = candles_df.copy()
    funding_rate_df = funding_rate_df.copy()
    funding_rate_df['fundingTime'] = pd.to_datetime(funding_rate_df['fundingTime'])
    candles_df['timestamp'] = pd.to_datetime(candles_df['timestamp'])
    merged = pd.merge_asof(candles_df.sort_values('timestamp'), funding_rate_df.sort_values('fundingTime'), left_on='timestamp', right_on='fundingTime', direction='backward')
    merged = merged.rename(columns={'fundingRate': 'funding_rate'})
    merged = merged.drop(columns=['fundingTime'])
    return merged

class CentralFeatureEngine:
    """
    Sistema centralizado de feature engineering
    - Calcula TODAS as features uma vez
    - Cache inteligente para performance
    - Valida√ß√£o de qualidade
    - Compatibilidade com todos os modelos
    """
    
    def __init__(self):
        self.feature_cache = {}
        self.calculation_history = {}
        self.feature_quality_scores = {}
        self.cache_hit_rate = 0.0
        self.last_cache_cleanup = datetime.now()
        
        # Configura√ß√µes
        self.cache_ttl = 300  # 5 minutos
        self.max_cache_size = 1000
        self.min_data_length = 20  # Reduzido para permitir testes com menos dados
        
        print("üöÄ Central Feature Engine inicializado")
    
    def enrich_with_advanced_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Enriquece dados com indicadores avan√ßados
        """
        df = df.copy()
        
        # Chama diretamente o m√©todo de features avan√ßadas
        return self._calculate_advanced_features(df)
    
    def get_all_features(self, data: pd.DataFrame, 
                        feature_set: str = 'complete',
                        use_cache: bool = True) -> pd.DataFrame:
        """
        Retorna todas as features necess√°rias
        
        Args:
            data: Dados OHLCV
            feature_set: 'basic', 'technical', 'advanced', 'complete'
            use_cache: Usar cache para performance
            
        Returns:
            DataFrame com todas as features
        """
        try:
            if data is None or len(data) < self.min_data_length:
                return pd.DataFrame()
            
            # Verifica cache
            cache_key = self._generate_cache_key(data, feature_set)
            if use_cache and cache_key in self.feature_cache:
                cached_result = self.feature_cache[cache_key]
                if self._is_cache_valid(cached_result):
                    self.cache_hit_rate = 0.8 * self.cache_hit_rate + 0.2
                    return cached_result['features'].copy()
            
            # Calcula features baseado no conjunto solicitado
            if feature_set == 'basic':
                features_df = self._calculate_basic_features(data)
            elif feature_set == 'technical':
                features_df = self._calculate_technical_features(data)
            elif feature_set == 'advanced':
                features_df = self._calculate_advanced_features(data)
            elif feature_set == 'complete':
                features_df = self._calculate_complete_features(data)
            else:
                features_df = self._calculate_complete_features(data)
            
            # Valida qualidade das features
            quality_score = self._validate_feature_quality(features_df)
            
            # Remove features com baixa qualidade
            features_df = self._remove_low_quality_features(features_df, quality_score)
            
            # Salva no cache
            if use_cache:
                self._save_to_cache(cache_key, features_df, quality_score)
            
            # Registra c√°lculo
            self._register_calculation(feature_set, len(features_df), quality_score)
            
            return features_df
            
        except Exception as e:
            print(f"‚ùå Erro no Central Feature Engine: {e}")
            return pd.DataFrame()
    
    def _calculate_basic_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """Features b√°sicas (8 features originais)"""
        df = data.copy()
        
        # Features b√°sicas OHLCV
        basic_features = ['open', 'high', 'low', 'close', 'volume']
        
        # RSI
        rsi = TechnicalIndicators.calculate_rsi(df['close'])
        if isinstance(rsi, (np.ndarray, list)):
            rsi = pd.Series(rsi, index=df.index[-len(rsi):])
        if len(rsi) < len(df):
            n_missing = len(df) - len(rsi)
            rsi = pd.concat([
                pd.Series([np.nan] * n_missing, index=df.index[:n_missing]),
                pd.Series(rsi.values, index=df.index[-len(rsi):])
            ])
            rsi.index = df.index
        df['rsi'] = rsi
        
        # Volatilidade
        df['volatility'] = df['close'].rolling(window=20).std()
        
        # Mudan√ßa de pre√ßo
        df['price_change_1'] = df['close'].pct_change()
        
        # Feature adicional para garantir 8 features
        df['sma_20'] = df['close'].rolling(window=20).mean()
        
        # Seleciona apenas features b√°sicas (8 features)
        feature_columns = basic_features + ['rsi', 'volatility', 'price_change_1', 'sma_20']
        
        # For√ßa a sele√ß√£o de 8 features fixas
        selected_features = ['open', 'high', 'low', 'close', 'volume', 'rsi', 'volatility', 'sma_20']
        
        # Garante que temos exatamente 8 features
        result = df[selected_features].copy()
        
        # Remove linhas com NaN, mas mant√©m pelo menos algumas linhas
        result = result.dropna()
        
        # Se n√£o temos dados suficientes ap√≥s dropna, preenche NaN com 0
        if len(result) < 5:
            result = df[selected_features].copy()
            result = result.fillna(0)
        
        # Garante que temos exatamente 8 colunas
        if len(result.columns) != 8:
            print(f"‚ö†Ô∏è Aviso: Central Feature Engine retornando {len(result.columns)} features em vez de 8")
            # Adiciona colunas extras se necess√°rio
            while len(result.columns) < 8:
                col_name = f'extra_feature_{len(result.columns)}'
                result[col_name] = 0.0
            # Remove colunas extras se necess√°rio
            if len(result.columns) > 8:
                result = result.iloc[:, :8]
        
        return result
    
    def _calculate_technical_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """Features t√©cnicas (indicadores tradicionais)"""
        df = data.copy()
        
        # ===== RSI MULTI-TIMEFRAME =====
        for period in [7, 14, 21]:
            rsi = TechnicalIndicators.calculate_rsi(df['close'], period)
            if isinstance(rsi, (np.ndarray, list)):
                rsi = pd.Series(rsi, index=df.index[-len(rsi):])
            if len(rsi) < len(df):
                n_missing = len(df) - len(rsi)
                rsi = pd.concat([
                    pd.Series([np.nan] * n_missing, index=df.index[:n_missing]),
                    pd.Series(rsi.values, index=df.index[-len(rsi):])
                ])
                rsi.index = df.index
            df[f'rsi_{period}'] = rsi
        
        # ===== MACD =====
        df['macd'], df['macd_signal'], df['macd_hist'] = self._calculate_macd(df['close'])
        
        # ===== BOLLINGER BANDS =====
        df['bb_upper'], df['bb_middle'], df['bb_lower'] = self._calculate_bollinger_bands(df['close'])
        df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle']
        df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])
        
        # ===== STOCHASTIC =====
        df['stoch_k'], df['stoch_d'] = self._calculate_stochastic(df['high'], df['low'], df['close'])
        
        # ===== MOVING AVERAGES =====
        for period in [5, 10, 20, 50]:
            df[f'sma_{period}'] = df['close'].rolling(period).mean()
            df[f'ema_{period}'] = df['close'].ewm(span=period).mean()
        
        # ===== VOLUME INDICATORS =====
        df['volume_sma'] = df['volume'].rolling(20).mean()
        df['volume_ratio'] = df['volume'] / df['volume_sma']
        df['obv'] = self._calculate_obv(df['close'], df['volume'])
        df['mfi'] = self._calculate_mfi(df['high'], df['low'], df['close'], df['volume'])
        
        return df
    
    def _calculate_atr(self, df, period=14):
        """Calcula ATR (Average True Range)"""
        try:
            high = df['high']
            low = df['low']
            close = df['close']
            
            tr1 = high - low
            tr2 = abs(high - close.shift(1))
            tr3 = abs(low - close.shift(1))
            
            tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
            atr = tr.rolling(period).mean()
            
            return atr
        except Exception:
            return pd.Series([np.nan] * len(df))
    
    def _calculate_cci(self, df, period=20):
        """Calcula CCI (Commodity Channel Index)"""
        try:
            typical_price = (df['high'] + df['low'] + df['close']) / 3
            sma = typical_price.rolling(period).mean()
            mad = typical_price.rolling(period).apply(lambda x: np.mean(np.abs(x - x.mean())))
            cci = (typical_price - sma) / (0.015 * mad)
            return cci
        except Exception:
            return pd.Series([np.nan] * len(df))
    
    def _calculate_williams_r(self, df, period=14):
        """Calcula Williams %R"""
        try:
            highest_high = df['high'].rolling(period).max()
            lowest_low = df['low'].rolling(period).min()
            williams_r = ((highest_high - df['close']) / (highest_high - lowest_low)) * -100
            return williams_r
        except Exception:
            return pd.Series([np.nan] * len(df))
    
    def _calculate_advanced_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """Features avan√ßadas (20+ features sofisticadas)"""
        try:
            df = data.copy()
            
            # Remove colunas n√£o num√©ricas para evitar erros
            numeric_columns = ['open', 'high', 'low', 'close', 'volume']
            df = df[numeric_columns].copy()
            
            # ===== INDICADORES AVAN√áADOS =====
            
            # ATR (Average True Range)
            df['atr_14'] = self._calculate_atr(df, 14)
            
            # ADX (Average Directional Index)
            df['adx_14'] = self._calculate_adx(df['high'], df['low'], df['close'], 14)
            
            # CCI (Commodity Channel Index)
            df['cci_20'] = self._calculate_cci(df, 20)
            
            # OBV (On Balance Volume)
            df['obv'] = self._calculate_obv(df['close'], df['volume'])
            
            # Williams %R
            df['williams_r_14'] = self._calculate_williams_r(df, 14)
            
            # ROC (Rate of Change)
            df['roc_10'] = self._calculate_roc(df['close'], 10)
            
            # Momentum
            df['mom_10'] = self._calculate_momentum(df['close'], 10)
            
            # TRIX
            df['trix_15'] = self._calculate_trix(df['close'], 15)
            
            # Ultimate Oscillator
            df['ultosc'] = self._calculate_ultosc(df['high'], df['low'], df['close'])
            
            # MFI (Money Flow Index)
            df['mfi_14'] = self._calculate_mfi(df['high'], df['low'], df['close'], df['volume'], 14)
            
            # Stochastic
            stoch_k, stoch_d = self._calculate_stochastic(df['high'], df['low'], df['close'])
            df['stoch_k_14'] = stoch_k
            df['stoch_d_14'] = stoch_d
            
            # Bollinger Bands
            bb_upper, bb_middle, bb_lower = self._calculate_bollinger_bands(df['close'])
            df['bb_upper_20'] = bb_upper
            df['bb_lower_20'] = bb_lower
            df['bb_middle_20'] = bb_middle
            # Evita divis√£o por zero
            df['bb_width_20'] = np.where(bb_middle != 0, (bb_upper - bb_lower) / bb_middle, 0)
            df['bb_position_20'] = np.where((bb_upper - bb_lower) != 0, (df['close'] - bb_lower) / (bb_upper - bb_lower), 0.5)
            
            # TRIX (adicionado explicitamente)
            df['trix_15'] = self._calculate_trix(df['close'], 15)
            
            # Remove valores NaN
            df = df.replace([np.inf, -np.inf], np.nan)
            df = df.fillna(0.0)
            
            return df
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro em features avan√ßadas: {e}")
            # Fallback para features b√°sicas
            return self._calculate_basic_features(data)
    
    def _calculate_complete_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """Features completas (todas as features dispon√≠veis)"""
        try:
            # Fallback direto para features b√°sicas para evitar erros
            return self._calculate_basic_features(data)
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro em features completas: {e}")
            # Fallback para features b√°sicas
            return self._calculate_basic_features(data)
    
    def _add_market_regime_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Features de regime de mercado"""
        volatility = df['close'].pct_change().rolling(20).std()
        trend = df['close'].rolling(20).mean().pct_change(20)
        
        # Regime classification
        df['market_regime'] = np.where(
            (volatility > volatility.quantile(0.7)) & (trend > trend.quantile(0.7)),
            'high_vol_bull',
            np.where(
                (volatility > volatility.quantile(0.7)) & (trend < trend.quantile(0.3)),
                'high_vol_bear',
                np.where(
                    (volatility < volatility.quantile(0.3)) & (trend > trend.quantile(0.7)),
                    'low_vol_bull',
                    np.where(
                        (volatility < volatility.quantile(0.3)) & (trend < trend.quantile(0.3)),
                        'low_vol_bear',
                        'sideways'
                    )
                )
            )
        )
        
        # Regime encoding
        regime_map = {
            'high_vol_bull': 1.0,
            'high_vol_bear': -1.0,
            'low_vol_bull': 0.5,
            'low_vol_bear': -0.5,
            'sideways': 0.0
        }
        df['regime_encoded'] = df['market_regime'].map(regime_map).fillna(0.0)
        # Remove colunas de string para evitar erros
        df = df.drop(['market_regime', 'vol_regime'], axis=1, errors='ignore')
        
        return df
    
    def _add_ml_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Features de machine learning"""
        # Price patterns
        df['price_pattern'] = np.where(
            (df['close'] > df['open']) & (df['close'] > df['close'].shift(1)),
            'bullish',
            np.where(
                (df['close'] < df['open']) & (df['close'] < df['close'].shift(1)),
                'bearish',
                'neutral'
            )
        )
        
        pattern_map = {'bullish': 1.0, 'bearish': -1.0, 'neutral': 0.0}
        df['pattern_encoded'] = df['price_pattern'].map(pattern_map).fillna(0.0)
        
        # Support and resistance
        df['support_level'] = df['low'].rolling(20).min()
        df['resistance_level'] = df['high'].rolling(20).max()
        df['support_distance'] = (df['close'] - df['support_level']) / df['close']
        df['resistance_distance'] = (df['resistance_level'] - df['close']) / df['close']
        
        # Mean reversion
        df['mean_reversion'] = (df['close'] - df['sma_20']) / df['sma_20']
        df['momentum_divergence'] = df['rsi_14'] - df['close'].pct_change(14) * 100
        
        return df
    
    def _add_statistical_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Features estat√≠sticas"""
        for period in [20, 50]:
            returns = df['close'].pct_change()
            df[f'skewness_{period}'] = returns.rolling(period).skew()
            df[f'kurtosis_{period}'] = returns.rolling(period).kurt()
            
            mean = df['close'].rolling(period).mean()
            std = df['close'].rolling(period).std()
            df[f'zscore_{period}'] = (df['close'] - mean) / std
            df[f'percentile_rank_{period}'] = df['close'].rolling(period).rank(pct=True)
        
        return df
    
    def _add_microstructure_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Features de microestrutura"""
        df['spread'] = df['high'] - df['low']
        df['spread_ratio'] = df['spread'] / df['close']
        df['volume_imbalance'] = df['volume'] * np.sign(df['close'] - df['open'])
        df['tick_direction'] = np.sign(df['close'].diff())
        
        return df
    
    def _add_lag_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Features de lag"""
        for lag in [1, 2, 3, 5, 10]:
            df[f'close_lag_{lag}'] = df['close'].shift(lag)
            df[f'volume_lag_{lag}'] = df['volume'].shift(lag)
            df[f'return_lag_{lag}'] = df['close'].pct_change().shift(lag)
        
        for period in [5, 10, 20]:
            returns = df['close'].pct_change()
            df[f'return_mean_{period}'] = returns.rolling(period).mean()
            df[f'return_std_{period}'] = returns.rolling(period).std()
            df[f'return_min_{period}'] = returns.rolling(period).min()
            df[f'return_max_{period}'] = returns.rolling(period).max()
        
        return df
    
    def _remove_string_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """Remove colunas que cont√™m strings para evitar erros de convers√£o"""
        try:
            # Identifica colunas num√©ricas
            numeric_columns = []
            for col in df.columns:
                try:
                    # Verifica se a coluna cont√©m apenas n√∫meros
                    sample_values = df[col].dropna().head(10)
                    if len(sample_values) > 0:
                        # Tenta converter para float
                        pd.to_numeric(sample_values, errors='raise')
                        numeric_columns.append(col)
                except (ValueError, TypeError):
                    # Coluna cont√©m strings, ignora
                    continue
            
            # Se n√£o encontrou colunas num√©ricas, usa fallback
            if not numeric_columns:
                basic_cols = ['open', 'high', 'low', 'close', 'volume', 'rsi', 'volatility', 'sma_20']
                numeric_columns = [col for col in basic_cols if col in df.columns]
            
            # Retorna apenas colunas num√©ricas
            result = df[numeric_columns].copy()
            
            # Remove linhas com NaN
            result = result.dropna()
            
            return result
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro removendo colunas de string: {e}")
            # Fallback: retorna apenas colunas b√°sicas
            basic_cols = ['open', 'high', 'low', 'close', 'volume']
            available_cols = [col for col in basic_cols if col in df.columns]
            return df[available_cols].copy()
    
    # ===== M√âTODOS AUXILIARES PARA C√ÅLCULOS =====
    
    def _calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> Tuple[pd.Series, pd.Series, pd.Series]:
        """Calcula MACD"""
        ema_fast = prices.ewm(span=fast).mean()
        ema_slow = prices.ewm(span=slow).mean()
        macd = ema_fast - ema_slow
        macd_signal = macd.ewm(span=signal).mean()
        macd_histogram = macd - macd_signal
        return macd, macd_signal, macd_histogram
    
    def _calculate_bollinger_bands(self, prices: pd.Series, period: int = 20, std_dev: float = 2) -> Tuple[pd.Series, pd.Series, pd.Series]:
        """Calcula Bollinger Bands"""
        sma = prices.rolling(window=period).mean()
        std = prices.rolling(window=period).std()
        upper_band = sma + (std * std_dev)
        lower_band = sma - (std * std_dev)
        return upper_band, sma, lower_band
    
    def _calculate_stochastic(self, high: pd.Series, low: pd.Series, close: pd.Series, 
                            k_period: int = 14, d_period: int = 3) -> Tuple[pd.Series, pd.Series]:
        """Calcula Stochastic"""
        lowest_low = low.rolling(window=k_period).min()
        highest_high = high.rolling(window=k_period).max()
        k_percent = 100 * ((close - lowest_low) / (highest_high - lowest_low))
        d_percent = k_percent.rolling(window=d_period).mean()
        return k_percent, d_percent
    
    def _calculate_obv(self, close: pd.Series, volume: pd.Series) -> pd.Series:
        """Calcula On-Balance Volume"""
        obv = pd.Series(index=close.index, dtype=float)
        obv.iloc[0] = volume.iloc[0]
        
        for i in range(1, len(close)):
            if close.iloc[i] > close.iloc[i-1]:
                obv.iloc[i] = obv.iloc[i-1] + volume.iloc[i]
            elif close.iloc[i] < close.iloc[i-1]:
                obv.iloc[i] = obv.iloc[i-1] - volume.iloc[i]
            else:
                obv.iloc[i] = obv.iloc[i-1]
        
        return obv
    
    def _calculate_mfi(self, high: pd.Series, low: pd.Series, close: pd.Series, volume: pd.Series, period: int = 14) -> pd.Series:
        """Calcula Money Flow Index"""
        typical_price = (high + low + close) / 3
        money_flow = typical_price * volume
        
        positive_flow = pd.Series(0.0, index=typical_price.index)
        negative_flow = pd.Series(0.0, index=typical_price.index)
        
        for i in range(1, len(typical_price)):
            if typical_price.iloc[i] > typical_price.iloc[i-1]:
                positive_flow.iloc[i] = money_flow.iloc[i]
            elif typical_price.iloc[i] < typical_price.iloc[i-1]:
                negative_flow.iloc[i] = money_flow.iloc[i]
        
        positive_mf = positive_flow.rolling(window=period).sum()
        negative_mf = negative_flow.rolling(window=period).sum()
        
        mfi = 100 - (100 / (1 + positive_mf / negative_mf))
        return mfi
    
    def _calculate_parkinson_volatility(self, high: pd.Series, low: pd.Series, period: int = 20) -> pd.Series:
        """Calcula Parkinson Volatility"""
        return np.sqrt(
            (1 / (4 * np.log(2))) * 
            ((np.log(high / low) ** 2).rolling(period).mean())
        )
    
    def _calculate_garman_klass_volatility(self, high: pd.Series, low: pd.Series, close: pd.Series, open_price: pd.Series, period: int = 20) -> pd.Series:
        """Calcula Garman-Klass Volatility"""
        return np.sqrt(
            (0.5 * (np.log(high / low) ** 2) - 
             (2 * np.log(2) - 1) * (np.log(close / open_price) ** 2)).rolling(period).mean()
        )
    
    def _calculate_adx(self, high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14) -> pd.Series:
        """Calcula ADX"""
        try:
            return talib.ADX(high, low, close, timeperiod=period)
        except:
            return pd.Series(50.0, index=high.index)
    
    def _calculate_roc(self, prices: pd.Series, period: int) -> pd.Series:
        """Calcula Rate of Change"""
        try:
            return talib.ROC(prices, timeperiod=period)
        except:
            return prices.pct_change(period) * 100
    
    def _calculate_momentum(self, prices: pd.Series, period: int) -> pd.Series:
        """Calcula Momentum"""
        try:
            return talib.MOM(prices, timeperiod=period)
        except:
            return prices - prices.shift(period)
    
    def _calculate_cmo(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """Calcula CMO"""
        try:
            return talib.CMO(prices, timeperiod=period)
        except:
            return pd.Series(0.0, index=prices.index)
    
    def _calculate_trix(self, prices: pd.Series, period: int = 30) -> pd.Series:
        """Calcula TRIX"""
        try:
            return talib.TRIX(prices, timeperiod=period)
        except:
            return pd.Series(0.0, index=prices.index)
    
    def _calculate_ultosc(self, high: pd.Series, low: pd.Series, close: pd.Series) -> pd.Series:
        """Calcula Ultimate Oscillator"""
        try:
            return talib.ULTOSC(high, low, close)
        except:
            return pd.Series(50.0, index=high.index)
    
    # ===== M√âTODOS DE CACHE E QUALIDADE =====
    
    def _generate_cache_key(self, data: pd.DataFrame, feature_set: str) -> str:
        """Gera chave √∫nica para cache"""
        data_hash = hash(str(data.tail(10).values.tobytes()))
        return f"{feature_set}_{data_hash}_{len(data)}"
    
    def _is_cache_valid(self, cached_result: Dict) -> bool:
        """Verifica se cache ainda √© v√°lido"""
        if 'timestamp' not in cached_result:
            return False
        
        age = datetime.now() - cached_result['timestamp']
        return age.total_seconds() < self.cache_ttl
    
    def _save_to_cache(self, key: str, features: pd.DataFrame, quality_score: float):
        """Salva resultado no cache"""
        self.feature_cache[key] = {
            'features': features.copy(),
            'timestamp': datetime.now(),
            'quality_score': quality_score
        }
        
        # Limpa cache se necess√°rio
        if len(self.feature_cache) > self.max_cache_size:
            self._cleanup_cache()
    
    def _cleanup_cache(self):
        """Limpa cache antigo"""
        current_time = datetime.now()
        keys_to_remove = []
        
        for key, value in self.feature_cache.items():
            age = current_time - value['timestamp']
            if age.total_seconds() > self.cache_ttl:
                keys_to_remove.append(key)
        
        for key in keys_to_remove:
            del self.feature_cache[key]
        
        self.last_cache_cleanup = current_time
    
    def _validate_feature_quality(self, features: pd.DataFrame) -> Dict[str, float]:
        """Valida qualidade das features"""
        quality_scores = {}
        
        for column in features.columns:
            if column in ['open', 'high', 'low', 'close', 'volume']:
                continue
            
            # Verifica se h√° muitos NaN
            nan_ratio = features[column].isna().sum() / len(features)
            
            # Verifica se h√° vari√¢ncia
            variance = features[column].var()
            
            # Verifica se h√° outliers extremos
            q1 = features[column].quantile(0.01)
            q99 = features[column].quantile(0.99)
            outlier_ratio = ((features[column] < q1) | (features[column] > q99)).sum() / len(features)
            
            # Score de qualidade
            quality_score = (1 - nan_ratio) * (1 - outlier_ratio) * min(variance, 1.0)
            quality_scores[column] = max(0.0, quality_score)
        
        return quality_scores
    
    def _remove_low_quality_features(self, features: pd.DataFrame, quality_scores: Dict[str, float]) -> pd.DataFrame:
        """Remove features com baixa qualidade"""
        good_features = []
        
        for column in features.columns:
            if column in ['open', 'high', 'low', 'close', 'volume']:
                good_features.append(column)
            elif quality_scores.get(column, 0.0) > 0.3:  # Threshold de qualidade
                good_features.append(column)
        
        return features[good_features].copy()
    
    def _register_calculation(self, feature_set: str, feature_count: int, quality_score: Dict[str, float]):
        """Registra c√°lculo para estat√≠sticas"""
        timestamp = datetime.now()
        
        self.calculation_history[timestamp] = {
            'feature_set': feature_set,
            'feature_count': feature_count,
            'avg_quality': np.mean(list(quality_score.values())) if quality_score else 0.0,
            'cache_hit_rate': self.cache_hit_rate
        }
        
        # Mant√©m apenas √∫ltimos 100 registros
        if len(self.calculation_history) > 100:
            oldest_key = min(self.calculation_history.keys())
            del self.calculation_history[oldest_key]
    
    def get_statistics(self) -> Dict[str, Any]:
        """Retorna estat√≠sticas do sistema"""
        return {
            'cache_size': len(self.feature_cache),
            'cache_hit_rate': self.cache_hit_rate,
            'total_calculations': len(self.calculation_history),
            'avg_feature_count': np.mean([calc['feature_count'] for calc in self.calculation_history.values()]) if self.calculation_history else 0,
            'avg_quality_score': np.mean([calc['avg_quality'] for calc in self.calculation_history.values()]) if self.calculation_history else 0.0,
            'last_cleanup': self.last_cache_cleanup
        }
    
    def clear_cache(self):
        """Limpa cache"""
        self.feature_cache.clear()
        print("üóëÔ∏è Cache limpo") 